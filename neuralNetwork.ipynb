{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Create a Model Class that inherits nn.Module\n",
    "\n",
    "class Model(nn.Module):\n",
    "    #Input layer (4 features flower) \n",
    "    #--> hidden layer1 (n neurons) --> H2 (n) \n",
    "    #--> output (3 types of iris flowers)\n",
    "    def __init__(self, in_features=4, h1=8, h2=9, out_features = 3):\n",
    "        super().__init__() # instantiate our nn.Module\n",
    "        self.fc1 = nn.Linear(in_features, h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.out =  nn.Linear(h2,out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Pick a manual seed for randomization\n",
    "torch.manual_seed(41)\n",
    "# Create an instance of model\n",
    "model = Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "my_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal.length  sepal.width  petal.length  petal.width  variety\n",
       "0             5.1          3.5           1.4          0.2      0.0\n",
       "1             4.9          3.0           1.4          0.2      0.0\n",
       "2             4.7          3.2           1.3          0.2      0.0\n",
       "3             4.6          3.1           1.5          0.2      0.0\n",
       "4             5.0          3.6           1.4          0.2      0.0\n",
       "..            ...          ...           ...          ...      ...\n",
       "145           6.7          3.0           5.2          2.3      2.0\n",
       "146           6.3          2.5           5.0          1.9      2.0\n",
       "147           6.5          3.0           5.2          2.0      2.0\n",
       "148           6.2          3.4           5.4          2.3      2.0\n",
       "149           5.9          3.0           5.1          1.8      2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change last colum from intergers\n",
    "my_df['variety'] = my_df['variety'].replace('Setosa', 0.0)\n",
    "my_df['variety'] = my_df['variety'].replace('Versicolor', 1.0)\n",
    "my_df['variety'] = my_df['variety'].replace('Virginica', 2.0)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Train test split! set X, y\n",
    "X = my_df.drop('variety', axis=1)\n",
    "y = my_df['variety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with sklearn\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert X to float tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_test = torch.FloatTensor(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to float tensors\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Set the criterion of model to mersure the error\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Choose Adam optimizer, lr = learning rate \n",
    "# if error does not go down after a bunch of iterations(epochs),\n",
    "# lower our learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 and loss: 1.125203251838684\n",
      "Epoch: 10 and loss: 1.0097211599349976\n",
      "Epoch: 20 and loss: 0.8162348866462708\n",
      "Epoch: 30 and loss: 0.585993230342865\n",
      "Epoch: 40 and loss: 0.4003389775753021\n",
      "Epoch: 50 and loss: 0.26794716715812683\n",
      "Epoch: 60 and loss: 0.1796349585056305\n",
      "Epoch: 70 and loss: 0.12165624648332596\n",
      "Epoch: 80 and loss: 0.08606516569852829\n",
      "Epoch: 90 and loss: 0.06522615253925323\n",
      "Epoch: 100 and loss: 0.05286873131990433\n",
      "Epoch: 110 and loss: 0.04508010298013687\n",
      "Epoch: 120 and loss: 0.03979312255978584\n",
      "Epoch: 130 and loss: 0.03596429154276848\n",
      "Epoch: 140 and loss: 0.03302798792719841\n",
      "Epoch: 150 and loss: 0.030512521043419838\n",
      "Epoch: 160 and loss: 0.027733495458960533\n",
      "Epoch: 170 and loss: 0.024612072855234146\n",
      "Epoch: 180 and loss: 0.021672405302524567\n",
      "Epoch: 190 and loss: 0.019319692626595497\n",
      "Epoch: 200 and loss: 0.017491867765784264\n",
      "Epoch: 210 and loss: 0.016043035313487053\n",
      "Epoch: 220 and loss: 0.014838052913546562\n",
      "Epoch: 230 and loss: 0.013799230568110943\n",
      "Epoch: 240 and loss: 0.012878721579909325\n",
      "Epoch: 250 and loss: 0.012150400318205357\n",
      "Epoch: 260 and loss: 0.011581881903111935\n",
      "Epoch: 270 and loss: 0.010989668779075146\n",
      "Epoch: 280 and loss: 0.01029115542769432\n",
      "Epoch: 290 and loss: 0.009702972136437893\n",
      "Epoch: 300 and loss: 0.009452791884541512\n",
      "Epoch: 310 and loss: 0.00888048391789198\n",
      "Epoch: 320 and loss: 0.008319300599396229\n",
      "Epoch: 330 and loss: 0.00825556181371212\n",
      "Epoch: 340 and loss: 0.0077691213227808475\n",
      "Epoch: 350 and loss: 0.00725496094673872\n",
      "Epoch: 360 and loss: 0.006883654277771711\n",
      "Epoch: 370 and loss: 0.006597006227821112\n",
      "Epoch: 380 and loss: 0.006293485872447491\n",
      "Epoch: 390 and loss: 0.0066731590777635574\n",
      "Epoch: 400 and loss: 0.005799316801130772\n",
      "Epoch: 410 and loss: 0.005588124506175518\n",
      "Epoch: 420 and loss: 0.005301742348819971\n",
      "Epoch: 430 and loss: 0.005058379843831062\n",
      "Epoch: 440 and loss: 0.004857606254518032\n",
      "Epoch: 450 and loss: 0.004658824298530817\n",
      "Epoch: 460 and loss: 0.0044699255377054214\n",
      "Epoch: 470 and loss: 0.004290001001209021\n",
      "Epoch: 480 and loss: 0.004118212498724461\n",
      "Epoch: 490 and loss: 0.003954293206334114\n",
      "Epoch: 500 and loss: 0.0037993600126355886\n",
      "Epoch: 510 and loss: 0.003842905629426241\n",
      "Epoch: 520 and loss: 0.00945970881730318\n",
      "Epoch: 530 and loss: 0.0056554037146270275\n",
      "Epoch: 540 and loss: 0.0038993696216493845\n",
      "Epoch: 550 and loss: 0.0033646235242486\n",
      "Epoch: 560 and loss: 0.00321375485509634\n",
      "Epoch: 570 and loss: 0.003143962938338518\n",
      "Epoch: 580 and loss: 0.0030750175938010216\n",
      "Epoch: 590 and loss: 0.003004194237291813\n",
      "Epoch: 600 and loss: 0.0029355650767683983\n",
      "Epoch: 610 and loss: 0.00286952150054276\n",
      "Epoch: 620 and loss: 0.002805572235956788\n",
      "Epoch: 630 and loss: 0.0027433468494564295\n",
      "Epoch: 640 and loss: 0.0026826595421880484\n",
      "Epoch: 650 and loss: 0.0026234672404825687\n",
      "Epoch: 660 and loss: 0.0025657182559370995\n",
      "Epoch: 670 and loss: 0.002509389305487275\n",
      "Epoch: 680 and loss: 0.0024544396437704563\n",
      "Epoch: 690 and loss: 0.002400836441665888\n",
      "Epoch: 700 and loss: 0.0023485540878027678\n",
      "Epoch: 710 and loss: 0.0022975101601332426\n",
      "Epoch: 720 and loss: 0.0022477367892861366\n",
      "Epoch: 730 and loss: 0.0021991990506649017\n",
      "Epoch: 740 and loss: 0.0021518454886972904\n",
      "Epoch: 750 and loss: 0.0021056346595287323\n",
      "Epoch: 760 and loss: 0.002060577040538192\n",
      "Epoch: 770 and loss: 0.0020166130270808935\n",
      "Epoch: 780 and loss: 0.0019737391266971827\n",
      "Epoch: 790 and loss: 0.001931927283294499\n",
      "Epoch: 800 and loss: 0.0018911114893853664\n",
      "Epoch: 810 and loss: 0.0018513178220018744\n",
      "Epoch: 820 and loss: 0.0018124758498743176\n",
      "Epoch: 830 and loss: 0.0017746029188856483\n",
      "Epoch: 840 and loss: 0.0017376603791490197\n",
      "Epoch: 850 and loss: 0.0017016127239912748\n",
      "Epoch: 860 and loss: 0.001666438882239163\n",
      "Epoch: 870 and loss: 0.0016321446746587753\n",
      "Epoch: 880 and loss: 0.001598669565282762\n",
      "Epoch: 890 and loss: 0.0015660005155950785\n",
      "Epoch: 900 and loss: 0.001534138573333621\n",
      "Epoch: 910 and loss: 0.0015030381036922336\n",
      "Epoch: 920 and loss: 0.001472689094953239\n",
      "Epoch: 930 and loss: 0.0014430851442739367\n",
      "Epoch: 940 and loss: 0.0014141888823360205\n",
      "Epoch: 950 and loss: 0.0013859779573976994\n",
      "Epoch: 960 and loss: 0.0013584584230557084\n",
      "Epoch: 970 and loss: 0.0013315815012902021\n",
      "Epoch: 980 and loss: 0.001305360347032547\n",
      "Epoch: 990 and loss: 0.0012797509552910924\n",
      "Epoch: 1000 and loss: 0.0012547613587230444\n",
      "Epoch: 1010 and loss: 0.0012303631519898772\n",
      "Epoch: 1020 and loss: 0.0012065268820151687\n",
      "Epoch: 1030 and loss: 0.0011832620948553085\n",
      "Epoch: 1040 and loss: 0.001160534331575036\n",
      "Epoch: 1050 and loss: 0.001138348481617868\n",
      "Epoch: 1060 and loss: 0.001116683124564588\n",
      "Epoch: 1070 and loss: 0.0010955171892419457\n",
      "Epoch: 1080 and loss: 0.0010748428758233786\n",
      "Epoch: 1090 and loss: 0.0010546580888330936\n",
      "Epoch: 1100 and loss: 0.0010349139338359237\n",
      "Epoch: 1110 and loss: 0.0010156483622267842\n",
      "Epoch: 1120 and loss: 0.0009968079393729568\n",
      "Epoch: 1130 and loss: 0.0009784068679437041\n",
      "Epoch: 1140 and loss: 0.0009604274528101087\n",
      "Epoch: 1150 and loss: 0.0009428500779904425\n",
      "Epoch: 1160 and loss: 0.0009256777702830732\n",
      "Epoch: 1170 and loss: 0.000908886082470417\n",
      "Epoch: 1180 and loss: 0.0008924761787056923\n",
      "Epoch: 1190 and loss: 0.0008764300146140158\n",
      "Epoch: 1200 and loss: 0.00086075539002195\n",
      "Epoch: 1210 and loss: 0.0008454195922240615\n",
      "Epoch: 1220 and loss: 0.0008304241928271949\n",
      "Epoch: 1230 and loss: 0.0008157528354786336\n",
      "Epoch: 1240 and loss: 0.0008014180930331349\n",
      "Epoch: 1250 and loss: 0.000787400349508971\n",
      "Epoch: 1260 and loss: 0.0007736827828921378\n",
      "Epoch: 1270 and loss: 0.0007602616678923368\n",
      "Epoch: 1280 and loss: 0.0007471253047697246\n",
      "Epoch: 1290 and loss: 0.0007342785247601569\n",
      "Epoch: 1300 and loss: 0.0007217152742668986\n",
      "Epoch: 1310 and loss: 0.000709426763933152\n",
      "Epoch: 1320 and loss: 0.0006973856361582875\n",
      "Epoch: 1330 and loss: 0.0006856115651316941\n",
      "Epoch: 1340 and loss: 0.0006740855751559138\n",
      "Epoch: 1350 and loss: 0.0006628046976402402\n",
      "Epoch: 1360 and loss: 0.0006517540896311402\n",
      "Epoch: 1370 and loss: 0.0006409490597434342\n",
      "Epoch: 1380 and loss: 0.0006303544505499303\n",
      "Epoch: 1390 and loss: 0.0006199959316290915\n",
      "Epoch: 1400 and loss: 0.0006098331650719047\n",
      "Epoch: 1410 and loss: 0.0005999011336825788\n",
      "Epoch: 1420 and loss: 0.0005901674157939851\n",
      "Epoch: 1430 and loss: 0.0005806298577226698\n",
      "Epoch: 1440 and loss: 0.0005712842685170472\n",
      "Epoch: 1450 and loss: 0.0005621261079795659\n",
      "Epoch: 1460 and loss: 0.000553166784811765\n",
      "Epoch: 1470 and loss: 0.0005443764966912568\n",
      "Epoch: 1480 and loss: 0.0005357704358175397\n",
      "Epoch: 1490 and loss: 0.0005273331189528108\n",
      "Epoch: 1500 and loss: 0.000519063847605139\n",
      "Epoch: 1510 and loss: 0.0005109654739499092\n",
      "Epoch: 1520 and loss: 0.0005030257161706686\n",
      "Epoch: 1530 and loss: 0.0004952375311404467\n",
      "Epoch: 1540 and loss: 0.0004876033344771713\n",
      "Epoch: 1550 and loss: 0.0004801251634489745\n",
      "Epoch: 1560 and loss: 0.00047278052079491317\n",
      "Epoch: 1570 and loss: 0.00046559315524064004\n",
      "Epoch: 1580 and loss: 0.0004585356218740344\n",
      "Epoch: 1590 and loss: 0.0004516247718129307\n",
      "Epoch: 1600 and loss: 0.00044483141391538084\n",
      "Epoch: 1610 and loss: 0.0004381801118142903\n",
      "Epoch: 1620 and loss: 0.00043165023089386523\n",
      "Epoch: 1630 and loss: 0.00042523801675997674\n",
      "Epoch: 1640 and loss: 0.00041895537287928164\n",
      "Epoch: 1650 and loss: 0.00041280072764493525\n",
      "Epoch: 1660 and loss: 0.00040674509364180267\n",
      "Epoch: 1670 and loss: 0.00040080558392219245\n",
      "Epoch: 1680 and loss: 0.00039497652323916554\n",
      "Epoch: 1690 and loss: 0.0003892568056471646\n",
      "Epoch: 1700 and loss: 0.0003836494288407266\n",
      "Epoch: 1710 and loss: 0.00037813500966876745\n",
      "Epoch: 1720 and loss: 0.00037273214547894895\n",
      "Epoch: 1730 and loss: 0.0003674202598631382\n",
      "Epoch: 1740 and loss: 0.00036220424226485193\n",
      "Epoch: 1750 and loss: 0.0003570863918866962\n",
      "Epoch: 1760 and loss: 0.0003520567261148244\n",
      "Epoch: 1770 and loss: 0.00034711736952885985\n",
      "Epoch: 1780 and loss: 0.00034227033029310405\n",
      "Epoch: 1790 and loss: 0.0003375116502866149\n",
      "Epoch: 1800 and loss: 0.0003328315797261894\n",
      "Epoch: 1810 and loss: 0.00032823506626300514\n",
      "Epoch: 1820 and loss: 0.00032372030545957386\n",
      "Epoch: 1830 and loss: 0.00031928325188346207\n",
      "Epoch: 1840 and loss: 0.00031492498237639666\n",
      "Epoch: 1850 and loss: 0.00031064572976902127\n",
      "Epoch: 1860 and loss: 0.000306433328660205\n",
      "Epoch: 1870 and loss: 0.00030230192351154983\n",
      "Epoch: 1880 and loss: 0.00029823469230905175\n",
      "Epoch: 1890 and loss: 0.00029424348031170666\n",
      "Epoch: 1900 and loss: 0.0002903205167967826\n",
      "Epoch: 1910 and loss: 0.0002864618436433375\n",
      "Epoch: 1920 and loss: 0.0002826674608513713\n",
      "Epoch: 1930 and loss: 0.0002789385325741023\n",
      "Epoch: 1940 and loss: 0.00027526894700713456\n",
      "Epoch: 1950 and loss: 0.0002716637391131371\n",
      "Epoch: 1960 and loss: 0.0002681190671864897\n",
      "Epoch: 1970 and loss: 0.0002646310022100806\n",
      "Epoch: 1980 and loss: 0.00026120152324438095\n",
      "Epoch: 1990 and loss: 0.0002578335697762668\n"
     ]
    }
   ],
   "source": [
    "# Train our model\n",
    "# Epochs? (one run thru all the trainingg data in our network)\n",
    "epochs = 2000\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    # Go forward and get a prediction\n",
    "    y_pred = model.forward(X_train) # Get predicted results\n",
    "\n",
    "    # Measure the loss/error, gonna be high at first value\n",
    "    loss = criterion(y_pred, y_train) # predicted values vs the y_train\n",
    "    # Keep track of our losses\n",
    "    losses.append(loss.detach().numpy())\n",
    "\n",
    "    # print every 10 epochs\n",
    "    if i % 10 == 0:\n",
    "        print(f'Epoch: {i} and loss: {loss}')\n",
    "    # Do some back propagations\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel(\"loss/error\")\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test data set (balidate model on test set)\n",
    "with torch.no_grad(): # Basically turn off back propagation\n",
    "    y_eval = model.forward(X_test) # X_test are features and y_eval predictions\n",
    "    loss = criterion(y_eval,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 tensor([-12.4805,  -2.9652,  24.6886]) \t Virginica \t 2\n",
      "2 tensor([-16.1016,  -9.4414,  37.2595]) \t Virginica \t 2\n",
      "3 tensor([-18.5919,  -9.9842,  41.8451]) \t Virginica \t 2\n",
      "4 tensor([ 20.0517,  34.5092, -26.9834]) \t Versicolor \t 1\n",
      "5 tensor([-15.5963,  -6.3379,  33.2230]) \t Virginica \t 2\n",
      "6 tensor([ 34.4656,  48.3861, -47.3411]) \t Versicolor \t 1\n",
      "7 tensor([-9.8049,  0.9733, 20.4942]) \t Virginica \t 2\n",
      "8 tensor([ 21.2115,  35.8659, -28.8054]) \t Versicolor \t 1\n",
      "9 tensor([-14.1691,  -4.0528,  28.5455]) \t Virginica \t 2\n",
      "10 tensor([-17.2296, -10.2248,  39.9023]) \t Virginica \t 2\n",
      "11 tensor([-5.3892,  5.7242, 13.3991]) \t Virginica \t 2\n",
      "12 tensor([ 143.7588,  130.5425, -177.9993]) \t Setosa \t 0\n",
      "13 tensor([ 130.5813,  118.3149, -161.5934]) \t Setosa \t 0\n",
      "14 tensor([ 40.2876,  50.3598, -54.0076]) \t Versicolor \t 1\n",
      "15 tensor([ 126.1264,  116.6581, -156.8263]) \t Setosa \t 0\n",
      "16 tensor([ 1.2833, 13.3884,  2.9005]) \t Virginica \t 1\n",
      "17 tensor([ 131.9224,  120.1853, -163.4690]) \t Setosa \t 0\n",
      "18 tensor([-9.0595,  1.1857, 19.0740]) \t Versicolor \t 2\n",
      "19 tensor([ 150.6627,  135.8279, -186.1878]) \t Setosa \t 0\n",
      "20 tensor([ 114.3219,  105.4382, -142.0648]) \t Setosa \t 0\n",
      "21 tensor([ 38.9629,  50.4775, -52.7064]) \t Versicolor \t 1\n",
      "22 tensor([-16.7876,  -8.5993,  37.4947]) \t Virginica \t 2\n",
      "23 tensor([ 127.3366,  117.4765, -158.2418]) \t Setosa \t 0\n",
      "24 tensor([ 138.4740,  125.4254, -171.3479]) \t Setosa \t 0\n",
      "25 tensor([ 40.1853,  52.2446, -54.4087]) \t Versicolor \t 1\n",
      "26 tensor([ 33.3992,  46.7735, -45.8792]) \t Versicolor \t 1\n",
      "27 tensor([ 17.6649,  32.2481, -22.9792]) \t Versicolor \t 1\n",
      "28 tensor([ 39.6829,  51.8394, -53.7885]) \t Versicolor \t 1\n",
      "29 tensor([ 142.4450,  129.2740, -176.3497]) \t Setosa \t 0\n",
      "30 tensor([ 15.3828,  29.1597, -19.5971]) \t Versicolor \t 1\n",
      "We got 28 correct out of 30\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(X_test):\n",
    "        y_val = model.forward(data)\n",
    "        if y_test[i] == 0:\n",
    "            x = \"Setosa\"\n",
    "        elif y_test[i] == 1:\n",
    "            x = 'Versicolor'\n",
    "        else: \n",
    "            x = 'Virginica'\n",
    "\n",
    "\n",
    "\n",
    "        # Will tell us what type of flower class our network thinks it is\n",
    "        print(f'{i+1} {str(y_val)} \\t {x} \\t {y_val.argmax().item()}')\n",
    "\n",
    "        # Correct or not\n",
    "        if y_val.argmax().item() == y_test[i]:\n",
    "            correct += 1\n",
    "print(f'We got {correct} correct out of {len(X_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_iris = torch.tensor([4.7, 3.2, 1.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newer_iris = torch.tensor([5.9, 3.0, 5.1, 1.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(newer_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our NN model\n",
    "torch.save(model.state_dict(), 'iris_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved\n",
    "new_model = Model()\n",
    "new_model.load_state_dict(torch.load('iris_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (fc2): Linear(in_features=8, out_features=9, bias=True)\n",
       "  (out): Linear(in_features=9, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure it loaded correctly\n",
    "new_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
